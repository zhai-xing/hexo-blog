{
    "version": "https://jsonfeed.org/version/1",
    "title": "Mo Bai • All posts by \"redis\" category",
    "description": "欢迎来到墨白的知识小屋，这里你可以阅读我的学习笔记并提出独到的见解~我们将互相学习交流知识，共同进步",
    "home_page_url": "https://zhai-xing.github.io/hexo-blog",
    "items": [
        {
            "id": "https://zhai-xing.github.io/hexo-blog/Redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0",
            "url": "https://zhai-xing.github.io/hexo-blog/Redis%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0",
            "title": "Redis学习笔记",
            "date_published": "2023-09-05T14:57:10.000Z",
            "content_html": "<h1 id=\"一-redis数据类型篇\"><a class=\"markdownIt-Anchor\" href=\"#一-redis数据类型篇\">#</a> 一、redis 数据类型篇</h1>\n<p>rdis 常见的数据类型及应用场景</p>\n<h4 id=\"string\"><a class=\"markdownIt-Anchor\" href=\"#string\">#</a> String</h4>\n<p>String 是最基本的 key-value 结构，key 是唯一标识 value 是具体的值 value 不仅是字符串，还可以是数字 (整数或者浮点数) value 最多可以容纳的数据长度是 512M，</p>\n<h5 id=\"内部实现\"><a class=\"markdownIt-Anchor\" href=\"#内部实现\">#</a> 内部实现：</h5>\n<p>String 底层实现的数据结构是 int 和 SDS (简单动态字符串)</p>\n<ul>\n<li>SDS 不仅可以保存文本数据还可以保存二进制数据，SDS 使用了 len 属性来判断字符串是否结束，</li>\n<li>SDS 获取字符串长度的时间复杂度是 O1</li>\n<li>Redis 的 SDS api 是安全的，拼接字符前会判断空间是否满足要求，不满足会自动扩容，所以不好导致缓冲区溢出</li>\n</ul>\n<h5 id=\"常用场景\"><a class=\"markdownIt-Anchor\" href=\"#常用场景\">#</a> 常用场景：</h5>\n<ul>\n<li>常规计数：计算点赞、转发、库存数量、阅读量</li>\n<li>分布式： 使用命令不存在此键就插入成功，而解锁 就是删除键，解锁的额操作需要判断，使用需要保证原子性操作，可以使用 Lua 脚本</li>\n<li>共享 Session 使用 Session 来保存用户的会话状态。</li>\n<li>热点数据缓存</li>\n</ul>\n<h4 id=\"list\"><a class=\"markdownIt-Anchor\" href=\"#list\">#</a> List</h4>\n<p>list 是简单的字符串列表，按照插入顺序排序，可以从头部或尾部向 List 添加元素，列最大长度为 2^32-1</p>\n<h5 id=\"内部实现-2\"><a class=\"markdownIt-Anchor\" href=\"#内部实现-2\">#</a> 内部实现</h5>\n<p>在 3.2 版本之前内部是采用双向链表或者压缩列表实现的，在后面就只用 quicklist 实现，替代了双向链表和压缩列表</p>\n<h5 id=\"常用场景-2\"><a class=\"markdownIt-Anchor\" href=\"#常用场景-2\">#</a> 常用场景</h5>\n<ul>\n<li>消息队列 ：如果要实现消息队列，需要实现消息的保序、可靠、处理重复的消息<br>\n保序的话，List 本身就是先进先出，已经是有序的了，并且 redis 提供了 BRPOP 命令，称为阻塞式读取，客户端在没有读到 redis 数据时自动阻塞，直到有数据了在读取。 处理重复消息，需要自己生成一个全局 ID，需要记录已经处理过的消息 ID. 而在消息可靠性方面，redis 在用户读取消息后就不会保存，若消费者消费失败消息就丢失了， 对于这个问题，可以再开一个消息队列，作为备份暂存，消费成功后再去删除掉备份的即可。<br>\n存在的问题</li>\n</ul>\n<ol>\n<li>无法支持消费者组</li>\n<li>无法支持多个消费者消费同一个消息</li>\n</ol>\n<h4 id=\"hash\"><a class=\"markdownIt-Anchor\" href=\"#hash\">#</a> Hash</h4>\n<p>Hash 是一个键值对集合，其中 value=[{field1,value1},{fieldN,valueN}]</p>\n<h5 id=\"内部实现-3\"><a class=\"markdownIt-Anchor\" href=\"#内部实现-3\">#</a> 内部实现</h5>\n<p>hash 类型的底层数据结构采用的是压缩列表或哈希表 。如果 hash 类型的元素格式小于 512 个 并且值小于 64 字节， 就使用压缩列表，反之则使用 hash 表 而在 redis7.0 中，压缩列表数据结构被废弃了，就采用 listpack 来实现</p>\n<h5 id=\"使用场景\"><a class=\"markdownIt-Anchor\" href=\"#使用场景\">#</a> 使用场景</h5>\n<p>通常用来缓存一些对象的属性，例如用户信息、购物车（用户 Id，商品 id，数量）</p>\n<h4 id=\"set\"><a class=\"markdownIt-Anchor\" href=\"#set\">#</a> Set</h4>\n<p>set 类型是无序唯一的键值集合，他的存储顺序不会按照插入的先后来存储，一个集合最多可存储 2^32-1 个元素，可以进行并交差集运算，也可以支持多个集合去交集、并集、差集。</p>\n<h5 id=\"应用场景\"><a class=\"markdownIt-Anchor\" href=\"#应用场景\">#</a> 应用场景</h5>\n<p>Set 类型比较适合用来做数据去重和保障数据的唯一性，还可以用来统计多个集合的交集、并集、补集，当我们存储的数据是无序且需要去重的情况下，比较适合使用集合类型来存储。需要注意 set 的集合计算复杂度较高，在数据量大的情况下，直接执行这些计算会导致 Redis 实例阻塞，</p>\n<ul>\n<li>点赞记录：一个用户只能对一篇文章点赞</li>\n<li>共同关注 ：交集</li>\n<li>抽奖活动：防止重复中奖</li>\n</ul>\n<h4 id=\"zset\"><a class=\"markdownIt-Anchor\" href=\"#zset\">#</a> Zset</h4>\n<p>zset 相比较与 set 类型多了一个排序属性，score 分值。对于有序集合 zset 每个存储元素相当于是有两个值组成，一个是有序集合的元素值，一个是排序值，</p>\n<h5 id=\"内部实现-4\"><a class=\"markdownIt-Anchor\" href=\"#内部实现-4\">#</a> 内部实现</h5>\n<p>内部采用了压缩列表或跳表实现的，若有有序集合元素个数小于 128 个。并且每个元素值小于 64 字节。redis 会使用压缩列表，否则则使用跳表。在 redis7.0 中跳表废弃了使用了 listpack 数据结构来实现</p>\n<h5 id=\"应用场景-2\"><a class=\"markdownIt-Anchor\" href=\"#应用场景-2\">#</a> 应用场景</h5>\n<p>排行榜、电话姓名、有序排列</p>\n<hr>\n<p>高级数据类型</p>\n<h4 id=\"bitmap\"><a class=\"markdownIt-Anchor\" href=\"#bitmap\">#</a> BitMap</h4>\n<p>位图，是一串连续的二进制数组 [0,1] 可以通过 offset 定位元素，BitMap 通过最小的单位 bit 来进行 0|1 的设置，表示某个元素的值或状态，时间复杂度为 O1,</p>\n<p>内部实现：本身利用了 String 作为底层数据结构，String 会保存为二进制的字节数组，redis 就把每个 bit 位利用起来，用来表示一个元素的二进制状态。</p>\n<p>应用场景：<br>\n签到打卡，判断用户登录状态 连续前端用户数，</p>\n<h4 id=\"hyperloglog\"><a class=\"markdownIt-Anchor\" href=\"#hyperloglog\">#</a> HyperLogLog</h4>\n<p>是一种用于统计基数的数据集合类型，基数统计是指统计一个集合中不重复元素个数， HyperLoglog 的统计规则是基于概率完成的，不是非常准确，而 HyperLogLog 的优点在于，输入元素的数量或体积很大时，计算基数所需要的内存空间是固定且很小的。<br>\n应用场景： 百万级 UV 网页计数</p>\n<h4 id=\"geo\"><a class=\"markdownIt-Anchor\" href=\"#geo\">#</a> GEO</h4>\n<p>这个是用于存储地理位置信息的，并可以对存储的信息进行计算操作，例如搜索附近的餐馆，打车等等。<br>\n内部原理：<br>\n底层采用了 Sorted Set 集合类型，GEO 类型使用了 GOEhash 编码方法实现了经纬度到 sorted set 中元素权重分数的转换，其中的两个关键机制计算对二维地图做区间划分和对区间进行编码。一组经纬度落在某个区间后，就用区间的编码值来标识。</p>\n<h4 id=\"stream\"><a class=\"markdownIt-Anchor\" href=\"#stream\">#</a> Stream</h4>\n<p>redis5. 新增的消息队列数据类型，用于完美地实现消息队列，它支持消息的持久化、支持自动生成全局唯一 ID、支持 ack 确认消息的模式、支持消费组模式等，让消息队列更加的稳定和可靠</p>\n<ul>\n<li>消息保序：XADD/XREAD</li>\n<li>阻塞读取：XREAD block</li>\n<li>重复消息处理：Stream 在使用 XADD 命令，会自动生成全局唯一 ID；</li>\n<li>消息可靠性：内部使用 PENDING List 自动保存消息，使用 XPENDING 命令查看消费组已经读取但是未被确认的消息，消费者使用 XACK 确认消息；</li>\n<li>支持消费组形式消费数据</li>\n</ul>\n<h1 id=\"二-redis数据结构篇\"><a class=\"markdownIt-Anchor\" href=\"#二-redis数据结构篇\">#</a> 二、Redis 数据结构篇</h1>\n<p>redis 本身就是一个键值型的数据结构<br>\n<img data-src=\"https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905225928934.png\" alt=\"image-20230905225928934\"></p>\n<ul>\n<li>redisDb 结构，表示 Redis 数据库的结构，结构体里存放了指向 dict 结构的指针。</li>\n<li>dict 结构，结构体里存放了 2 个哈希表，正常情况下都是用哈希表 1，哈希表 2 再 rehash 的时候才会使用</li>\n<li>dictht 结构表示哈希表的结构，结构体存放了哈希表数组，每个数组都指向应该哈希表节点的结构体指针 dictEntry 结构，表示哈希表节点的结构，结构里存放了 **void * key 和 void * value 指针， key 指向的是 String 对象，而 value 则可以指向 String 对象，也可以指向集合类型的对象，比如 List 对象、Hash 对象、Set 对象和 Zset 对象。<br>\n<img data-src=\"https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905225939660.png\" alt=\"image-20230905225939660\"></li>\n</ul>\n<h3 id=\"sds\"><a class=\"markdownIt-Anchor\" href=\"#sds\">#</a> SDS</h3>\n<p>redis 是使用 C 语言实现的，但是他没有直接使用 C 语言的 char* 字符数组，而是自己封装了一个名为简单动态字符串的数据结构，来表示字符串， 也就是 SDS<br>\n 不使用 c 语言的默认字符数组是因为:</p>\n<ol>\n<li>C 语言默认的字符数组是以 \\0 表示结束的，在二进制数据中经常有 \\0 这样的数据串，使用就不能保存</li>\n<li>C 语言的字符串是不会记录自身的缓冲区大小的。容易发生溢出</li>\n<li>字符串操作函数不高效且不安全，比如有缓冲区溢出的风险，有可能会造成程序运行终止<br>\n<img data-src=\"https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905225948684.png\" alt=\"image-20230905225948684\"></li>\n</ol>\n<ul>\n<li>SDS 的自动扩容机制 如果所需要的长度小于 1mb 。那么是翻倍扩容，如果超过 1Mb 是按照 newlen=1mb</li>\n<li>flags，用来表示不同类型的 SDS。一共设计了 5 种类型，分别是 sdshdr5、sdshdr8、sdshdr16、sdshdr32 和 sdshdr64，这 5 种类型的主要区别就在于，它们数据结构中的 len 和 alloc 成员变量的数据类型不同。\n<ul>\n<li>sdshdr16 类型的 len 和 alloc 的数据类型都是 uint16_t，表示字符数组长度和分配空间大小不能超过 2 的 16 次方。</li>\n<li>sdshdr32 则都是 uint32_t，表示表示字符数组长度和分配空间大小不能超过 2 的 32 次方。</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"链表\"><a class=\"markdownIt-Anchor\" href=\"#链表\">#</a> 链表</h3>\n<p>redis 的链表结构很简单，就前置节点，后置节点，数据；但是封装了一个 List 数据结构</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">typedef struct list &#123;</span><br><span class=\"line\">    //链表头节点</span><br><span class=\"line\">    listNode *head;</span><br><span class=\"line\">    //链表尾节点</span><br><span class=\"line\">    listNode *tail;</span><br><span class=\"line\">    //节点值复制函数</span><br><span class=\"line\">    void *(*dup)(void *ptr);</span><br><span class=\"line\">    //节点值释放函数</span><br><span class=\"line\">    void (*free)(void *ptr);</span><br><span class=\"line\">    //节点值比较函数</span><br><span class=\"line\">    int (*match)(void *ptr, void *key);</span><br><span class=\"line\">    //链表节点数量</span><br><span class=\"line\">    unsigned long len;</span><br><span class=\"line\">&#125; list;</span><br></pre></td></tr></table></figure>\n<p><img data-src=\"https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230013442.png\" alt=\"image-20230905230013442\"></p>\n<ul>\n<li>ListNode 链表节点的结构里设置有 prev 和 next，获取某个节点的前置节点或后置节点的时间复杂度只需要 O (1)；</li>\n<li>listl 因为有表头指针和标为指针，所以获取表头和表尾节点的时间复杂度是 O (1)</li>\n<li>list 结构因为提供了链表节点数量 len，所以获取链表中的节点数量的时间复杂度只需 O (1)；</li>\n</ul>\n<h3 id=\"压缩列表\"><a class=\"markdownIt-Anchor\" href=\"#压缩列表\">#</a> 压缩列表</h3>\n<p>压缩列表的最大特点就是他被设计成一种内存紧凑型的数据结构，占用的是一块连续的内存空间，不仅可以利用 CPU 缓存，而且可以针对不同的长度的数据进行相应编码，这种方式可以有效的节省内存开销。<br>\n<img data-src=\"https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230025692.png\" alt=\"image-20230905230025692\"></p>\n<ul>\n<li>zlbytes 记录整个压缩列表占用内存对内存字节数</li>\n<li>zltail 记录压缩列表尾部节点距离起始地址由多少字节，也就是列尾偏移量，</li>\n<li>zllen：记录压缩列表包含的节点数量</li>\n<li>zlend: 标记压缩列表的结束点 1</li>\n<li>压缩列表查找表头和表尾元素很快，只需要 O (1) 但是查找其他元素就没那么快了，因此压缩列表不适合保存过多元素</li>\n</ul>\n<h3 id=\"哈希表\"><a class=\"markdownIt-Anchor\" href=\"#哈希表\">#</a> 哈希表</h3>\n<p>哈希表是一种保存键值对（key-value）的数据结构。<br>\n哈希表中的每一个 key 都是独一无二的，程序可以根据 key 查找到与之关联的 value，或者通过 key 来更新 value，又或者根据 key 来删除整个 key-value 等等。<br>\n<img data-src=\"https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230038715.png\" alt=\"image-20230905230038715\"></p>\n<ul>\n<li>redis 采用了链式哈希的方式来解决冲突，</li>\n<li>不过，链式哈希局限性也很明显，随着链表长度的增加，在查询这一位置上的数据的耗时就会增加，毕竟链表的查询的时间复杂度是 O (n)。</li>\n</ul>\n<p>随着链表越来越长，hash 的查找速度也就会降低，redis 这里提供了 rehash 也就是上面提到的。</p>\n<h4 id=\"rehash\"><a class=\"markdownIt-Anchor\" href=\"#rehash\">#</a> rehash</h4>\n<p><img data-src=\"https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230048637.png\" alt=\"image-20230905230048637\"><br>\n 其实整个备份就是来做数据迁移了，节点太多 hash 桶太少，需要扩容<br>\n - 随着数据逐步增多，触发了 rehash 操作，这个过程分为三步：</p>\n<ul>\n<li>给「哈希表 2」 分配空间，一般会比「哈希表 1」 大 2 倍；</li>\n<li>将「哈希表 1 」的数据迁移到「哈希表 2」 中；</li>\n<li>迁移完成后，「哈希表 1 」的空间会被释放，并把「哈希表 2」 设置为「哈希表 1」，然后在「哈希表 2」 新创建一个空白的哈希表，为下次 rehash 做准备</li>\n<li>为了避免在 rehash 在数据迁移是，因为拷贝数据导致 redis 性能下降，所以都是采用的渐进式 hash，迁移工作是分多次完成，</li>\n</ul>\n<p>触发 rehash 时机：<br>\n<img data-src=\"https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230059484.png\" alt=\"image-20230905230059484\"></p>\n<ul>\n<li>当负载因子大于等于 1 ，并且 Redis 没有在执行 bgsave 命令或者 bgrewiteaof 命令，也就是没有执行 RDB 快照或没有进行 AOF 重写的时候，就会进行 rehash 操作。</li>\n<li>当负载因子大于等于 5 时，此时说明哈希冲突非常严重了，不管有没有有在执行 RDB 快照或 AOF 重写，都会强制进行 rehash 操作</li>\n</ul>\n<h3 id=\"整数集合\"><a class=\"markdownIt-Anchor\" href=\"#整数集合\">#</a> 整数集合</h3>\n<p>整数集合是 Set 对象的底层实现之一，当一个 Set 对象只包含整数值元素，并且元素数量不大时，就用整数集这个数据结构作为底层实现之一，整数集合本质上是一块连续的内存空间吗，整数集合会有一个升级规则，就是当我们将一个新元素加入到整数集合里面，如果新元素的类型（int32_t）比整数集合现有所有元素的类型（int16_t）都要长时，整数集合需要先进行升级，也就是按新元素的类型（int32_t）扩展 contents 数组的空间大小，然后才能将新元素加入到整数集合里，当然升级的过程中，也要维持整数集合的有序性</p>\n<h3 id=\"跳表\"><a class=\"markdownIt-Anchor\" href=\"#跳表\">#</a> 跳表</h3>\n<p><img data-src=\"https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230108527.png\" alt=\"image-20230905230108527\"><br>\n 链表在查找元素的时候，因为需要逐一查找，所以查找效率非常低下，时间复杂度是 O (n) ，跳表是链表的改进版<br>\n，多层有序链表，redis 中只有 Zset 用到了跳表，，个人感觉应该是基于链表的二分查找，redis 为什么使用跳表，而不使用红黑树来实现有序集合。</p>\n<ol>\n<li>有序集合主要是有增、删、改、查四个操作，这些操作红黑树和跳表时间复杂度都是一样的</li>\n<li>但是基于区间的查询，红黑树的效率就太低了，所以使用跳表</li>\n</ol>\n<h3 id=\"quicklist\"><a class=\"markdownIt-Anchor\" href=\"#quicklist\">#</a> quickList</h3>\n<p>quicklist 其实是双向链表和压缩列表的组合，一个 quicklist 就是一个链表，而链表中每个元素又是一个压缩列表，<br>\n压缩列表的不足，如果保存的元素太多，或者元素变大，压缩列表会有连锁更新的情况，quicklist 解决办法，通过控制每个链表节点中的压缩列表的大小或者元素个数，来规避连锁更新的问题。因为压缩列表元素越少或越小，连锁更新带来的影响就越小，从而提供了更好的访问性能。<br>\n<img data-src=\"https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230119103.png\" alt=\"image-20230905230119103\"></p>\n<h3 id=\"listpack\"><a class=\"markdownIt-Anchor\" href=\"#listpack\">#</a> listpack</h3>\n<p>是为了解决压缩列表出现的连锁更新问题，目的是替代压缩列表，它最大特点是 listpack 中每个节点不再包含前一个节点的长度了，压缩列表每个节点正因为需要保存前一个节点的长度字段，就会有连锁更新的隐患<br>\n<img data-src=\"https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230130155.png\" alt=\"image-20230905230130155\"><br>\nlistpack 没有压缩列表中记录前一个节点长度的字段了，listpack 只记录当前节点的长度，当我们向 listpack 加入一个新元素的时候，不会影响其他节点的长度字段的变化，从而避免了压缩列表的连锁更新问题。</p>\n<h1 id=\"三-reids-持久化\"><a class=\"markdownIt-Anchor\" href=\"#三-reids-持久化\">#</a> 三、Reids 持久化</h1>\n<h2 id=\"aof持久化\"><a class=\"markdownIt-Anchor\" href=\"#aof持久化\">#</a> AOF 持久化</h2>\n<p>redis 每执行一条写操作，就把该命令，以追加的方式写入到一个文件，然后后重启 redis 时，先去读这个这个文件里的命令并执行<br>\n配置文件中开启</p>\n <figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">appendonly yes</span><br><span class=\"line\">appendfilename &quot;appendonly.aof&quot;</span><br></pre></td></tr></table></figure>\n<p><img data-src=\"https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230142284.png\" alt=\"image-20230905230142284\"><br>\n 写入数据到数据库和写 aof 日志都是在主进程中完成的，有一定性能损失。当然 redis 也提供了其他的写回机制，可以配置，在 redis .conf 中配置 appendfsync</p>\n<ul>\n<li>Always，这个单词的意思是「总是」，所以它的意思是每次写操作命令执行完后，同步将 AOF 日志数据写回硬盘；</li>\n<li>Everysec，这个单词的意思是「每秒」，所以它的意思是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，然后每隔一秒将缓冲区里的内容写回到硬盘；</li>\n<li>No，意味着不由 Redis 控制写回硬盘的时机，转交给操作系统控制写回的时机，也就是每次写操作命令执行完后，先将命令写入到 AOF 文件的内核缓冲区，再由操作系统决定何时将缓冲区内容写回硬盘。<br>\n<img data-src=\"https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230149806.png\" alt=\"image-20230905230149806\"></li>\n</ul>\n<h4 id=\"aof重写机制\"><a class=\"markdownIt-Anchor\" href=\"#aof重写机制\">#</a> AOF 重写机制</h4>\n<p>AOF 日志是一个文件，随着执行的写操作命令越来越多，文件的大小会越来越大。Redis 为了避免 AOF 文件越写越大，提供了 AOF 重写机制，当 AOF 文件的大小超过所设定的阈值后，Redis 就会启用 AOF 重写机制，来压缩 AOF 文件。<br>\nredis 的重写机制是在后方子进程 bgrewriteaof 来完成的，<br>\n<img data-src=\"https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230157631.png\" alt=\"image-20230905230157631\"></p>\n<h2 id=\"rdb持久化\"><a class=\"markdownIt-Anchor\" href=\"#rdb持久化\">#</a> RDB 持久化</h2>\n<p>RDB 是内存快照，就是记录一个瞬间的东西，记录的是实时数据，与 AOF 不同，AOF 记录的是命令操作日志，而不是实际的数据。在回复数据时，RDB 要快一些，只需要将 RDB 文件读入内存就可以了，不需要像 AOF 一样还需要执行额外的操作命令。</p>\n<h3 id=\"如何生成rdb\"><a class=\"markdownIt-Anchor\" href=\"#如何生成rdb\">#</a> 如何生成 RDB</h3>\n<p>redis 提供了两个命令，分别是 save 和 bgsave，执行了 save 命令会在主线程上生成 rdb 文件，如果写入 rdb 文件太多会阻塞主线程。执行 bgsave 是创建了一个进程来生成 rdb 文件，这样可以避免主线程阻塞。<br>\n也可以通过配置文件的选项，每隔一段时间自动执行 bgsave 命令，因为 RDB 快照是全量快照的方式，因此执行的频率不能太频繁，否则会影响 Redis 性能，</p>\n<ul>\n<li>执行快照是 redis 的数据是可以继续呗修改的，因为采用了写时复制技术，<br>\n执行 bgsave 命令的时候，会通过 fork () 创建子进程，此时子进程和父进程是共享同一片内存数据的，因为创建  子进程的时候，会复制父进程的页表，但是页表指向的物理内存还是一个。共享的内存当另一部分被用户修改时，因为采用了写时复制，所以做复制功能的线程也会被同步。</li>\n</ul>\n<h2 id=\"混合持久化\"><a class=\"markdownIt-Anchor\" href=\"#混合持久化\">#</a> 混合持久化</h2>\n<p>尽管 RDB 比 AOF 的数据恢复速度快，但是快照的频率不好把握：</p>\n<p>如果频率太低，两次快照间一旦服务器发生宕机，就可能会比较多的数据丢失；<br>\n如果频率太高，频繁写入磁盘和创建子进程会带来额外的性能开销。<br>\n这是 redis4.0 提出来的，在配置文件中开启</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">aof-use-rdb-preamble yes</span><br></pre></td></tr></table></figure>\n<p>当开启了混合持久化时，在 AOF 重写日志时，fork 出来的重写子进程会先将与主线程共享的内存数据以 RDB 方式写入到 AOF 文件，然后主线程处理的操作命令会被记录在重写缓冲区里，重写缓冲区里的增量命令会以 AOF 方式写入到 AOF 文件，写入完成后通知主进程将新的含有 RDB 格式和 AOF 格式的 AOF 文件替换旧的的 AOF 文件。</p>\n<h1 id=\"功能篇\"><a class=\"markdownIt-Anchor\" href=\"#功能篇\">#</a> 功能篇</h1>\n<h3 id=\"过期删除策略\"><a class=\"markdownIt-Anchor\" href=\"#过期删除策略\">#</a> 过期删除策略</h3>\n<h5 id=\"定时删除\"><a class=\"markdownIt-Anchor\" href=\"#定时删除\">#</a> 定时删除</h5>\n<p>在设置 key 的过期时间时，同时创建一个定时事件，当到达时，由事件处理器执行 key 的删除操作</p>\n<ul>\n<li>优点：内存可以被尽快地释放。定时删除对内存是最友好的。</li>\n<li>缺点：定时删除策略对 CPU 不友好，删除过期 key 可能会占用相当一部分 CPU 时间，CPU 紧张的情况下将 CPU 用于删除和当前任务无关的过期键上，会对服务器的响应时间和吞吐量造成影响。</li>\n</ul>\n<h5 id=\"惰性删除\"><a class=\"markdownIt-Anchor\" href=\"#惰性删除\">#</a> 惰性删除</h5>\n<p>不主动删除过期健，每次从数据库访问 key 时检查是否过期，过期则删除，</p>\n<ul>\n<li>\n<p>优点：只会使用很少的系统资源，对 CPU 最友好。</p>\n</li>\n<li>\n<p>缺点：如果一个 key 已经过期，而这个 key 又仍然保留在数据库中，那么只要这个过期 key 一直没有被访问，它所占用的内存就不会释放。惰性删除策略对内存不友好。</p>\n</li>\n</ul>\n<h5 id=\"定期删除\"><a class=\"markdownIt-Anchor\" href=\"#定期删除\">#</a> 定期删除</h5>\n<p>每隔段时间随机从数据库中取出一定数量的 key 进行检查，并删除其中过期的 key</p>\n<ul>\n<li>优点：限制删除操作执行的时长和频率来减少删除操作对 CPU 的影响，同时也能删除一部分过期的数据减少了过期键对空间的无效占用。</li>\n<li>缺点：内存清理方面没有定时删除效果好，同时没有惰性删除使用的系统资源少。难以确定删除操作执行的时长和频率</li>\n</ul>\n<h5 id=\"定期删除惰性删除配合使用\"><a class=\"markdownIt-Anchor\" href=\"#定期删除惰性删除配合使用\">#</a> 定期删除 + 惰性删除配合使用</h5>\n<p>redis 选择的时惰性删除 + 定期删除，配合使用，<br>\nRedis 在访问或者修改 key 之前，都会调用 expireIfNeeded 函数对其进行检查，检查 key 是否过期：</p>\n<ul>\n<li>如果过期，则删除该 key，然后返回 null 客户端；</li>\n<li>如果没有过期，不做任何处理，然后返回正常的键值对给客户端</li>\n</ul>\n<p>从过期字典中随机抽取 20 个 key；检查这 20 个 key 是否过期，并删除已过期的 key；已过期 key 的数量占比随机抽取 key 的数量大于 25%，则继续重复步骤直到比重小于 25%。</p>\n<h3 id=\"redis-事务\"><a class=\"markdownIt-Anchor\" href=\"#redis-事务\">#</a> redis 事务</h3>\n<p>严格来说 redis 事务只是个批处理，有隔离性但是没有原子性<br>\n Multi：开启事务<br>\n Exec：执行<br>\n Discard: 不执行<br>\n redis 和 lus 脚本可以进行整合 (用到再学)</p>\n<h3 id=\"redis的持久化\"><a class=\"markdownIt-Anchor\" href=\"#redis的持久化\">#</a> redis 的持久化</h3>\n<p>redis 是 nosql 数据库，需要把数据保存到磁盘。<br>\nredis 所有的数据都是保存在内存中，保存的数据量取决于内存的容量。<br>\nredis 提供了两种持久化机制：</p>\n<ul>\n<li>\n<p>RDB: 默认开启，快照模式</p>\n</li>\n<li>\n<p>AOF：日志存储，把对 redis 的操作的命令以日志方式存储到文件，当需要恢复数据时，从头到尾把命令执行一遍， 需要手动开启，</p>\n</li>\n<li>\n<p>注：如果同时开启了 RBD 和 AOF 默认是使用 aof 恢复数据。</p>\n</li>\n</ul>\n<h4 id=\"rdb默认使用\"><a class=\"markdownIt-Anchor\" href=\"#rdb默认使用\">#</a> RDB（默认使用）</h4>\n<p>RDB 方式是通过快照（ snapshotting ）完成的，当符合一定条件时 Redis 会自动将内存中的数据进行，快照并持久化到硬盘<br>\n执行时机：</p>\n<ol>\n<li>符合指定配置的快照规则</li>\n<li>执行 save 或 bgsave 命令 save 主线程去快照 bgsave 调用异步线程去快照<br>\n主线程是单线程 4.0 I/O 操作 已经有多线程概念</li>\n<li>执行 flushall 或 flushdb</li>\n<li>执行主从复制操作</li>\n</ol>\n<p>可以手动控制快照规则<br>\n save 多少秒内 数据变了多少<br>\n save “” : 不使用 RDB 存储<br>\n save 900 1 ： 表示 15 分钟（900 秒钟）内至少 1 个键被更改则进行快照。<br>\nsave 300 10 ： 表示 5 分钟（300 秒）内至少 10 个键被更改则进行快照。<br>\nsave 60 10000 ：表示 1 分钟内至少 10000 个键被更改则进行快照。</p>\n<p>快照过程：</p>\n<ol>\n<li>redis 调用系统中的 fork 函数复制一份当前进程的副本（子进程）</li>\n<li>父进程继续接收客户端的发来的命令，而子进程则开始将内存中的数据写入到硬盘中的临时文件，</li>\n<li>当子进程写完所有的数据后，会用临时文件替换掉旧的 rdb 文件，至此一次快照完成。</li>\n</ol>\n<p>rdb 的优缺点<br>\n优点：<br>\nRDB 可以最大化 Redis 的性能：父进程在保存 RDB 文件时唯一要做的就是 fork 出一个子进<br>\n程，然后这个子进程就会处理接下来的所有保存工作，父进程无需执行任何磁盘 I/O 操作.</p>\n<p>缺点：使用 RDB 方式实现持久化，一旦 Redis 异常退出，就会丢失最后一次快照以后更改的所有数据，如果数据集比较大的时候， fork 可以能比较耗时，造成服务器在一段时间内停<br>\n止处理客户端的请求；</p>\n<h4 id=\"aof\"><a class=\"markdownIt-Anchor\" href=\"#aof\">#</a> AOF</h4>\n<p>默认情况下 Redis 没有开启 AOF （ append only file ）方式的持久化。<br>\n开启 AOF 持久化后，每执行一条会更改 Redis 中的数据的命令， Redis 就会将该命令写入硬盘中的 AOF 文件，这一过程会降低 Redis 的性能，但大部分情况下这个影响是能够接受的，另外使用较快的硬盘可以提高 AOF 的性能。<br>\nRedis 每次更改数据的时候， aof 机制都会将命令记录到 aof 文件，但是实际上由于操作系统的缓存机制，数据并没有实时写入到硬盘，而是进入硬盘缓存。再通过硬盘缓存机制去刷新到保存到文件。</p>\n<h4 id=\"混合持久化方式\"><a class=\"markdownIt-Anchor\" href=\"#混合持久化方式\">#</a> 混合持久化方式</h4>\n<p>这是在 4.0 之后的新版本中新增的。混合持久化是结合了 RDB 和 AOF 的优点，在写入的时候，先把当前的数据以 RDB 的形式写入文件的开头，再将后续的操作命令以 AOF 的格式存入文件，这样既能保证 Redis 重启时的速度，又能减低数据丢失的风险。<br>\n有两种开启方式：<br>\n1、通过命令行开启；<br>\n2、通过配置文件开启</p>\n<h2 id=\"redis-集群模式\"><a class=\"markdownIt-Anchor\" href=\"#redis-集群模式\">#</a> Redis 集群模式</h2>\n<h3 id=\"主从复制\"><a class=\"markdownIt-Anchor\" href=\"#主从复制\">#</a> 主从复制</h3>\n<h3 id=\"哨兵集群\"><a class=\"markdownIt-Anchor\" href=\"#哨兵集群\">#</a> 哨兵集群</h3>\n<h3 id=\"redis-cluster-集群\"><a class=\"markdownIt-Anchor\" href=\"#redis-cluster-集群\">#</a> Redis Cluster 集群</h3>\n<h4 id=\"集群介绍\"><a class=\"markdownIt-Anchor\" href=\"#集群介绍\">#</a> 集群介绍</h4>\n<h5 id=\"1-搭建主从\"><a class=\"markdownIt-Anchor\" href=\"#1-搭建主从\">#</a> 1、搭建主从</h5>\n<p>主节点：</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">port 8001</span><br><span class=\"line\">daemonize no</span><br><span class=\"line\">protected-mode no</span><br></pre></td></tr></table></figure>\n<h5 id=\"1-搭建分片集群\"><a class=\"markdownIt-Anchor\" href=\"#1-搭建分片集群\">#</a> 1、搭建分片集群</h5>\n<p>测试是在一台服务器上同时启动多个 redis 实例完成的，当然也可以使用多个服务器目前条件有限，<br>\n1）先下载安装一台单机的 redis</p>\n<ol>\n<li>安装 GCC 环境<br>\n yum install -y gcc-c++<br>\nyum install -y wget</li>\n<li>下载并解压缩 Redis 源码压缩包<br>\n wget <span class=\"exturl\" data-url=\"aHR0cDovL2Rvd25sb2FkLnJlZGlzLmlvL3JlbGVhc2VzL3JlZGlzLTUuMC40LnRhci5neg==\">http://download.redis.io/releases/redis-5.0.4.tar.gz</span><br>\ntar -zxf redis-5.0.4.tar.gz<br>\n3. 编译原码<br>\n cd redis-5.0.4<br>\nmake<br>\n4. 安装 Redis ，需要通过 PREFIX 指定安装路径，如果不指定默认是安装到 /usr/lcoal/bin 启动的适合不太方便<br>\n make install PREFIX=/kkb/server/redis<br>\n 这步做完最好把安装包里面的 redis.conf 文件复制一份到安装目录下的 bin 目录中，这样启动就方便很多<br>\n 5. 修改配置文件参数</li>\n</ol>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># 将`daemonize`由`no`改为`yes`</span><br><span class=\"line\">daemonize yes</span><br><span class=\"line\"># 默认绑定的是回环地址，默认不能被其他机器访问</span><br><span class=\"line\"># bind 127.0.0.1</span><br><span class=\"line\"># 是否开启保护模式，由yes该为no</span><br><span class=\"line\">protected-mode no</span><br></pre></td></tr></table></figure>\n<p>6. 启动服务<br>\n./redis-server redis.conf<br>\n7. 关闭服务<br>\n./redis-cli shutdown<br>\n 这样单机就搭建完成了。下面是集群</p>\n<p>2）将 bin 目录下的数据持久化文件删掉，在启动集群前要保证是一台全新的 redis. 只保留以下 7 个文件</p>\n<p><img data-src=\"https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230250244.png\" alt=\"image-20230905230250244\"><br>\n3) 将 bin 目录复制 6 份，分别命名 1-6，修改每个目录里面的 redi-conf 文件，将端口号分别改为 8801-8806<br>\n 将配置文件中的 设置为此 cluster-enable yes<br>\n 另外需要关闭防火墙，或者设置白名单，开启端口等等。不然多个服务器之间集群无法访问</p>\n<p>4） 启动所有的 redis，我这里写了一个脚本启动</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">cd bin-1</span><br><span class=\"line\">chmod 777 redis-server</span><br><span class=\"line\">./redis-server redis.conf</span><br><span class=\"line\">cd ..</span><br><span class=\"line\">cd bin-2</span><br><span class=\"line\">chmod 777 redis-server</span><br><span class=\"line\">./redis-server redis.conf</span><br><span class=\"line\">cd ..</span><br><span class=\"line\">cd bin-3</span><br><span class=\"line\">chmod 777 redis-server</span><br><span class=\"line\">./redis-server redis.conf</span><br><span class=\"line\">cd ..</span><br><span class=\"line\">cd bin-4</span><br><span class=\"line\">chmod 777 redis-server</span><br><span class=\"line\">./redis-server redis.conf</span><br><span class=\"line\">cd ..</span><br><span class=\"line\">cd bin-5</span><br><span class=\"line\">chmod 777 redis-server</span><br><span class=\"line\">./redis-server redis.conf</span><br><span class=\"line\">cd ..</span><br><span class=\"line\">cd bin-6</span><br><span class=\"line\">chmod 777 redis-server</span><br><span class=\"line\">./redis-server redis.conf</span><br><span class=\"line\">cd ..</span><br></pre></td></tr></table></figure>\n<p>5）进入 bin-1 中，使用以下命令，创建集群</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">./redis-cli --cluster create 192.168.1.110:8001 192.168.1.110:8002 192.168.1.110:8003 192.168.1.110:8004 192.168.1.110:8005 192.168.1.110:8006 --cluster-replicas 1</span><br></pre></td></tr></table></figure>\n<p>最后的参数 1 表示 每个 redis 有一个备份 当主机挂了，备份定上，这也是为什么需要 6 个的原因，<br>\n6) 如下图，在过程中输入 yes 启动成功<br>\n<img data-src=\"https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230303127.png\" alt=\"image-20230905230303127\"><br>\n<img data-src=\"https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230310340.png\" alt=\"image-20230905230310340\"><br>\n<img data-src=\"https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230318236.png\" alt=\"image-20230905230318236\"></p>\n<h4 id=\"2-连接集群\"><a class=\"markdownIt-Anchor\" href=\"#2-连接集群\">#</a> 2、连接集群</h4>\n<p>连接集群中任意一台机器都行，例如使用 cli 连接 8001 机器<br>\n./redis-cli -h 192.168.1.110 -p 8001 -c<br>\n 连接集群一定要加 - c 这个参数，不然插入会报错，因为集群模式下，每次新增键都需要进行插槽计算。如果用可视化也是需要集群模式连接<br>\n<img data-src=\"https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230325571.png\" alt=\"image-20230905230325571\"><br>\n 使用 Java 去连接时，需要将所以的节点列出来，然后他会自己去选择连接</p>\n<h4 id=\"3-查看集群状态\"><a class=\"markdownIt-Anchor\" href=\"#3-查看集群状态\">#</a> 3、查看集群状态</h4>\n<h4 id=\"4-集群优缺点\"><a class=\"markdownIt-Anchor\" href=\"#4-集群优缺点\">#</a> 4、集群优缺点</h4>\n<p>客户端与 Redis 节点直连，不需要中间 Proxy 层，直接连接任意一个 Master 节点<br>\n根据公式 HASH_SLOT=CRC16 (key) mod 16384，计算出映射到哪个分片上，然后 Redis 会去相应的节<br>\n点进行操作<br>\n优点:<br>\n(1) 无需 Sentinel 哨兵监控，如果 Master 挂了，Redis Cluster 内部自动将 Slave 切换 Master<br>\n (2) 可以进行水平扩容<br>\n (3) 支持自动化迁移，当出现某个 Slave 宕机了，那么就只有 Master 了，这时候的高可用性就无法很好的保证<br>\n了，万一 Master 也宕机了，咋办呢？ 针对这种情况，如果说其他 Master 有多余的 Slave ，集群自动把多余<br>\n的 Slave 迁移到没有 Slave 的 Master 中。<br>\n缺点:<br>\n(1) 批量操作是个坑<br>\n (2) 资源隔离性较差，容易出现相互影响的情况。</p>\n<h2 id=\"redis数据存储细节\"><a class=\"markdownIt-Anchor\" href=\"#redis数据存储细节\">#</a> redis 数据存储细节</h2>\n<p>redis 的一个 DB 就是一个 HashTable,<br>\n 一个 hashtable 由 1 个 dict 结构、2 个 dictht 结构、1 个 dictEntry 指针数组（称为 bucket）和多个 dictEntry 结构组成<br>\n dictEntry 结构用于保存键值对，结构定义如下：<br>\n<img data-src=\"https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230336488.png\" alt=\"image-20230905230336488\"></p>\n<h4 id=\"redis的对象类型与内存编码\"><a class=\"markdownIt-Anchor\" href=\"#redis的对象类型与内存编码\">#</a> redis 的对象类型与内存编码</h4>\n<p>Redis 支持 5 种对象类型，而每种结构都有至少两种编码</p>\n<ol>\n<li>\n<p>String<br>\n 字符串是最基础的类型，因为所有的键都是字符串类型，且字符串之外的其他几种复杂类型的元素也是字符串<br>\n字符串长度不能超过 512MB。有三种编码 分别是 int ;embstr ;raw; 数据比较少时使用 embstr 数据比较多时使用 raw<br>\nkey-value<br>\nSDS 结构体进行存储</p>\n</li>\n<li>\n<p>List<br>\n 列表（list）用来存储多个有序的字符串，每个字符串称为元素；<br>\n一个列表可以存储 2^64-1 个元素。<br>\nRedis 中的列表支持两端插入和弹出，并可以获得指定位置（或范围）的元素，可以充当数组、队列、栈等。<br>\nRedis3.0 之前列表的内部编码可以是压缩列表（ziplist）或双端链表（linkedlist）但是在 3.2 版本之后 因为转换也 是个费时且复杂的操作，引入了一种新的数据格式，结合了双向列表 linkedlist 和 ziplist 的特点，称之为 quicklist。有 的节点都用 quicklist 存储，省去了到临界条件是的格式转换。<br>\n压缩列表（ziplist）是 Redis 为了节省内存而开发的，是由一系列特殊编码的连续内存块组成的顺序型数据结<br>\n构，一个压缩列表可以包含任意多个节点（entry），每个节点可以保存一个字节数组或者一个整数值，放到一个连续内存区。当一个列表只包含少量列表项时，并且每个列表项时小整数值或短字符串，那么 Redis 会使用压缩列表来做该列表的底层实现，<br>\n 目前使用的是 quicklist 我们仍旧可以将其看作一个双向列表，但是列表的每个节点都是一个 ziplist，其实就是<br>\n linkedlist 和 ziplist 的结合。quicklist 中的每个节点 ziplist 都能够存储多个数据元素。<br>\nRedis3.2 开始，列表采用 quicklist 进行编码。<br>\n<img data-src=\"https://blog-1259743669.cos.ap-chengdu.myqcloud.com/image-20230905230344677.png\" alt=\"image-20230905230344677\"></p>\n</li>\n<li>\n<p>Hash</p>\n</li>\n</ol>\n<ul>\n<li>Redis 中内层的哈希既可能使用哈希表，也可能使用压缩列表。</li>\n<li>只有同时满足下面两个条件时，才会使用压缩列表：</li>\n</ul>\n<ol>\n<li>\n<p>哈希中元素数量小于 512 个；</p>\n</li>\n<li>\n<p>哈希中所有键值对的键和值字符串长度都小于 64 字节。</p>\n</li>\n<li>\n<p>Set<br>\n 但集合与列表有两点不同：集合中的元素是无序的，因此不能通过索引来操作元素；集合中的元素不能有重复。<br>\nintSet: 集合中的元素都是数值类型<br>\n只有同时满足下面两个条件时，集合才会使用整数集合：</p>\n</li>\n<li>\n<p>集合中元素数量小于 512 个；</p>\n</li>\n<li>\n<p>集合中所有元素都是整数值。<br>\n如果有一个条件不满足，则使用哈希表；且编码只可能由整数集合转化为哈希表，反方向则不可能。</p>\n</li>\n<li>\n<p>ZSet<br>\n 有序集合的内部编码可以是压缩列表（ziplist）或跳跃表（skiplist）。<br>\n只有同时满足下面两个条件时，才会使用压缩列表：<br>\n1）有序集合中元素数量小于 128 个；<br>\n2）有序集合中 所有成员长度都不足 64 字节 。<br>\n如果有一个条件不满足，则使用跳跃表；且编码只可能由压缩列表转化为跳跃表，反方向则不可能。</p>\n</li>\n</ol>\n<h4 id=\"跳表-zskiplist\"><a class=\"markdownIt-Anchor\" href=\"#跳表-zskiplist\">#</a> 跳表 zskiplist：</h4>\n<p>类似于折半查找</p>\n<h2 id=\"redis性能优化简单学了点\"><a class=\"markdownIt-Anchor\" href=\"#redis性能优化简单学了点\">#</a> redis 性能优化（简单学了点）</h2>\n<h3 id=\"优化内存占用\"><a class=\"markdownIt-Anchor\" href=\"#优化内存占用\">#</a> 优化内存占用</h3>\n<ol>\n<li>利用 jemalloc 内存分配器（默认使用）</li>\n<li>能用整形 / 长整型的尽量使用，减少使用字符串</li>\n<li>利用共享对象，引用常量池</li>\n<li>缩短键值对的存储长度（减少 key 的长度）</li>\n</ol>\n<h3 id=\"性能优化\"><a class=\"markdownIt-Anchor\" href=\"#性能优化\">#</a> 性能优化</h3>\n<ol>\n<li>设置键值的过期时间</li>\n<li>使用 lazy free 特性，（惰性删除），不是马上删掉，而是放到删除队列里面，一起删除，或者是开子线程删除。</li>\n<li>限制 redis 内存大小，设置内存淘汰策略</li>\n<li>禁用长耗时的查询命令</li>\n<li>使用 slowlog 优化耗时命令</li>\n<li>避免大量数据同时失效</li>\n<li>使用 Pipeline 批量操作数据</li>\n<li>客户端使用连接池优化</li>\n<li>使用分布式架构来增加读写速度</li>\n<li>禁用 THP 特性 /*</li>\n</ol>\n",
            "tags": [
                "原理",
                "学习笔记"
            ]
        }
    ]
}